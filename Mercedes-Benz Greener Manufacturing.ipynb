{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wFwZMobS5Ndb"
      },
      "outputs": [],
      "source": [
        "# Step1: Import the required libraries\n",
        "\n",
        "# linear algebra\n",
        "import numpy as np\n",
        "# data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import pandas as pd\n",
        "# for dimensionality reduction\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step2: Read the data from train.csv\n",
        "\n",
        "df_train = pd.read_csv('train.csv')\n",
        "# let us understand the data\n",
        "print('Size of training set: {} rows and {} columns'\n",
        "      .format(*df_train.shape))\n",
        "# print few rows and see how the data looks like\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "FQPH0yFb5ViJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step3: Collect the Y values into an array\n",
        "\n",
        "# seperate the y from the data as we will use this to learn as\n",
        "# the prediction output\n",
        "y_train = df_train['y'].values\n"
      ],
      "metadata": {
        "id": "KyX-I9hU5cOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step4: Understand the data types we have\n",
        "\n",
        "# iterate through all the columns which has X in the name of the column\n",
        "cols = [c for c in df_train.columns if 'X' in c]\n",
        "print('Number of features: {}'.format(len(cols)))\n",
        "\n",
        "print('Feature types:')\n",
        "df_train[cols].dtypes.value_counts()"
      ],
      "metadata": {
        "id": "cz3Zp8gn5hoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step5: Count the data in each of the columns\n",
        "\n",
        "counts = [[], [], []]\n",
        "for c in cols:\n",
        "    typ = df_train[c].dtype\n",
        "    uniq = len(np.unique(df_train[c]))\n",
        "    if uniq == 1:\n",
        "        counts[0].append(c)\n",
        "    elif uniq == 2 and typ == np.int64:\n",
        "        counts[1].append(c)\n",
        "    else:\n",
        "        counts[2].append(c)\n",
        "\n",
        "print('Constant features: {} Binary features: {} Categorical features: {}\\n'\n",
        "      .format(*[len(c) for c in counts]))\n",
        "print('Constant features:', counts[0])\n",
        "print('Categorical features:', counts[2])"
      ],
      "metadata": {
        "id": "U6r7HLdZ5pJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step6: Read the test.csv data\n",
        "\n",
        "df_test = pd.read_csv('test.csv')\n",
        "\n",
        "# remove columns ID and Y from the data as they are not used for learning\n",
        "usable_columns = list(set(df_train.columns) - set(['ID', 'y']))\n",
        "y_train = df_train['y'].values\n",
        "id_test = df_test['ID'].values\n",
        "\n",
        "x_train = df_train[usable_columns]\n",
        "x_test = df_test[usable_columns]\n"
      ],
      "metadata": {
        "id": "nsZaD9Mj5vdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step7: Check for null and unique values for test and train sets\n",
        "\n",
        "def check_missing_values(df):\n",
        "    if df.isnull().any().any():\n",
        "        print(\"There are missing values in the dataframe\")\n",
        "    else:\n",
        "        print(\"There are no missing values in the dataframe\")\n",
        "check_missing_values(x_train)\n",
        "check_missing_values(x_test)\n"
      ],
      "metadata": {
        "id": "7pqQo2ap5zpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step8: If for any column(s), the variance is equal to zero,\n",
        "# then you need to remove those variable(s).\n",
        "# Apply label encoder\n",
        "\n",
        "for column in usable_columns:\n",
        "    cardinality = len(np.unique(x_train[column]))\n",
        "    if cardinality == 1:\n",
        "        x_train.drop(column, axis=1) # Column with only one\n",
        "        # value is useless so we drop it\n",
        "        x_test.drop(column, axis=1)\n",
        "    if cardinality > 2: # Column is categorical\n",
        "        mapper = lambda x: sum([ord(digit) for digit in x])\n",
        "        x_train[column] = x_train[column].apply(mapper)\n",
        "        x_test[column] = x_test[column].apply(mapper)\n",
        "x_train.head()"
      ],
      "metadata": {
        "id": "D_4O3KOL534X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step9: Make sure the data is now changed into numericals\n",
        "\n",
        "print('Feature types:')\n",
        "x_train[cols].dtypes.value_counts()\n"
      ],
      "metadata": {
        "id": "UvalUPzK58Kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step10: Perform dimensionality reduction\n",
        "# Linear dimensionality reduction using Singular Value Decomposition of\n",
        "# the data to project it to a lower dimensional space.\n",
        "n_comp = 12\n",
        "pca = PCA(n_components=n_comp, random_state=420)\n",
        "pca2_results_train = pca.fit_transform(x_train)\n",
        "pca2_results_test = pca.transform(x_test)\n"
      ],
      "metadata": {
        "id": "ljyO7Oox6AhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step11: Training using xgboost\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "        pca2_results_train,\n",
        "        y_train, test_size=0.2,\n",
        "        random_state=4242)\n",
        "\n",
        "d_train = xgb.DMatrix(x_train, label=y_train)\n",
        "d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
        "#d_test = xgb.DMatrix(x_test)\n",
        "d_test = xgb.DMatrix(pca2_results_test)\n",
        "\n",
        "params = {}\n",
        "params['objective'] = 'reg:linear'\n",
        "params['eta'] = 0.02\n",
        "params['max_depth'] = 4\n",
        "\n",
        "def xgb_r2_score(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    return 'r2', r2_score(labels, preds)\n",
        "\n",
        "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
        "\n",
        "clf = xgb.train(params, d_train,\n",
        "                1000, watchlist, early_stopping_rounds=50,\n",
        "                feval=xgb_r2_score, maximize=True, verbose_eval=10)\n"
      ],
      "metadata": {
        "id": "LgnOMSFT6EKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step12: Predict your test_df values using xgboost\n",
        "\n",
        "p_test = clf.predict(d_test)\n",
        "\n",
        "sub = pd.DataFrame()\n",
        "sub['ID'] = id_test\n",
        "sub['y'] = p_test\n",
        "sub.to_csv('xgb.csv', index=False)\n",
        "\n",
        "sub.head()\n"
      ],
      "metadata": {
        "id": "UdFhw0I26MVS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}